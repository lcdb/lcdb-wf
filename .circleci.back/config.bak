version: 2

variables:

  # default settings for all steps
  defaults: &defaults
    docker:
      - image: continuumio/miniconda3

  # --------------------------------------------------------------------------
  # The caching dramatically speeds up testing time, because we can do the
  # time-consuming step of conda environment creation once and then use that
  # for subsequent steps. It works like this:
  #
  # The `initial-setup` job (defined in workflows below) saves the cache when
  # it's done. Here the cache is the miniconda directory. Later jobs
  # (chipseq-step, rnaseq-step, etc) restore that cache to dramatically speed
  # up testing time.
  #
  # The cache key is set to only re-make the cache when the relevant files
  # change. There's also a `v1-` prefix. This should be changed once in a while
  # just to re-trigger an environment rebuild (say, when some critical updates
  # hit bioconda).
  #
  # See https://circleci.com/docs/2.0/caching for details.

  save_cache: &save_cache
    save_cache:
      key: v4-{{ checksum "env.yml" }}-{{ checksum "env-r.yml" }}
      paths:
        - /opt/conda

        # this file is created by sra-tools upon installation by conda, and so
        # needs to be included in the cache otherwise fastq-dump thinks it's
        # mis-configured.
        - /root/.ncbi/user-settings.mkfg

  restore_cache: &restore_cache
    restore_cache:
      keys:
        - v4-{{ checksum "env.yml" }}-{{ checksum "env-r.yml" }}

  # --------------------------------------------------------------------------
  # The path needs to be set each time; in jobs below this will be called as
  # one of the first steps in each job.
  set-path: &set-path
      run:
        name: Set path
        command: |
          # x11-utils required to avoid R::png() segfaulting
          apt update && apt install -y locales-all locales rsync x11-utils
          echo 'export DEPLOY=/tmp/lcdb-wf-test' >> $BASH_ENV
          echo 'export LCDBWF_ENV=lcdb-wf-test' >> $BASH_ENV
          echo 'export LCDBWF_ENV_R=lcdb-wf-test-r' >> $BASH_ENV
          echo 'export LC_ALL=en_US.utf8' >> $BASH_ENV
          echo 'export LANG=en_US.utf8' >> $BASH_ENV
          echo 'export ORIG=$(pwd)' >> $BASH_ENV
          source $BASH_ENV
  # --------------------------------------------------------------------------
  # Set up conda if the environments do not already exist
  setup: &setup
    run:
      name: Setup conda
      command: |
        set -e
        source $BASH_ENV
        # We only do the installation if the conda environment does not already
        # exist.
        if ! conda env list | grep -q "lcdb-wf-test"; then
            echo "Setting up conda..."
            conda update conda
            conda config --system --add channels defaults
            conda config --system --add channels bioconda
            conda config --system --add channels conda-forge
            conda config --system --set channel_priority strict
            conda install gcc mamba yaml -y
            which mamba
            mamba --version
            mamba env create -n $LCDBWF_ENV --file env.yml
            mamba env create -n $LCDBWF_ENV_R --file env-r.yml
        fi

  # --------------------------------------------------------------------------
  # Deploy into a new directory and get the test data.
  get-data: &get-data
    run:
      name: Download example data
      command: |
        conda info --envs
        source activate lcdb-wf-test

        # rsync is required for the deployment process
        apt install -y rsync

        # Deploy to the new directory, so we are testing the real-world case of post-deployment.
        # Note that $DEPLOY is set in the "set-paths" step configured above.
        python deploy.py --flavor full --dest $DEPLOY --branch $CIRCLE_BRANCH --clone

        # Separately copy over some test-specific files
        cp workflows/chipseq/run_test.sh $DEPLOY/workflows/chipseq
        cp workflows/rnaseq/run_test.sh $DEPLOY/workflows/rnaseq
        cp workflows/rnaseq/run_downstream_test.sh $DEPLOY/workflows/rnaseq
        cp workflows/colocalization/run_test.sh $DEPLOY/workflows/references
        cp workflows/colocalization/run_test.sh $DEPLOY/workflows/colocalization
        mkdir $DEPLOY/ci
        mkdir $DEPLOY/test
        cp test/lcdb-wf-test $DEPLOY/test
        cp test/workflow_test_params.yaml $DEPLOY/test
        cp ci/get-data.py $DEPLOY/ci

        # the ./run_test.sh scripts run this
        cp ci/preprocessor.py $DEPLOY/ci

        # download example data
        cd $DEPLOY
        test/lcdb-wf-test data --kind=all --verbose

  # --------------------------------------------------------------------------
  # Run the doctests across the included modules
  pytest-step: &pytest-step
    run:
      name: Run pytest suite and testthat suite
      command: |
        source activate lcdb-wf-test

        echo LCDBWF_ENV_R=$LCDBWF_ENV_R
        echo LCDBWF_ENV=$LCDBWF_ENV

        # run unit tests and doctests for the modules in lib
        test/lcdb-wf-test unit_tests --pytest

        # Ensure that the chunks in rnaseq.Rmd have matching documentation
        test/lcdb-wf-test unit_tests --ensure-docs

        # find all URLs in reference configs and make sure they exist
        test/lcdb-wf-test unit_tests --url-check

        # run R package unit tests using the R env
        test/lcdb-wf-test unit_tests --r-test


  # --------------------------------------------------------------------------
  # Standard chipseq workflow
  chipseq-step: &chipseq-step
      run:
        name: chipseq workflow
        command: |
          cd $DEPLOY/workflows/chipseq
          source activate lcdb-wf-test
          $DEPLOY/test/lcdb-wf-test chipseq --run-workflow --use-conda -j2 -k -p -r
          $DEPLOY/test/lcdb-wf-test chipseq --trackhub

  # --------------------------------------------------------------------------
  # Previous versions had an error where chipseq peaks needed to be defined for
  # every caller. This does a (relatively) quick test to only run a single
  # sample through a single peak-caller to prevent regression of that error
  chipseq-misc-step: &chipseq-misc-step
      run:
        name: chipseq misc
        command: |
          cd $DEPLOY/workflows/chipseq
          source activate lcdb-wf-test
          ./run_test.sh --use-conda -j2 -k -p -r \
            --configfile $ORIG/test/test_configs/test_chipseq_regression.yaml \
            --config sampletable=$ORIG/test/test_configs/chipseq_one_run.tsv \
            merged_bigwigs="{}" \
            --until bed_to_bigbed

          # Piggy-backing on that test, here we check to make sure it's OK to
          # omit peak-calling config. We just do a dry-run.
          #
          # NOTE: this fails in recent versions of Snakemake, see
          # https://github.com/snakemake/snakemake/issues/1815. Disabling the
          # test for now...
          if false; then
            ./run_test.sh -n \
              --configfile $ORIG/test/test_configs/test_chipseq_no_peaks.yaml \
              --config sampletable=$ORIG/test/test_configs/chipseq_one_run.tsv \
              merged_bigwigs="{}" \
              --until bed_to_bigbed
          fi

  # --------------------------------------------------------------------------
  # Standard references workflow.
  references-step: &references-step
      run:
        name: references workflow
        command: |
          source activate lcdb-wf-test
          $DEPLOY/test/lcdb-wf-test references --run-workflow --configfile=config/config.yaml -j2 -p -r -k --orig $ORIG

  # --------------------------------------------------------------------------
  # Standard RNA-seq workflow
  rnaseq-step: &rnaseq-step
      run:
        name: rnaseq workflow
        command: |
          cd $DEPLOY
          source activate lcdb-wf-test
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow -n
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --use-conda -j2 -k -p -r --orig $ORIG

          $DEPLOY/test/lcdb-wf-test rnaseq --trackhub --orig $ORIG

          # This run the preprocessor on the Rmd files and stores them
          # in a new download-test directory (see the comments in the script
          # for details)
          $DEPLOY/test/lcdb-wf-test rnaseq --downstream

          # bundle up the entire directory to be used as an artifact
          tar -zcf downstream.tar.gz workflows/rnaseq/downstream-test/

  # --------------------------------------------------------------------------
  # Various tests on RNA-seq workflow that don't warrant the overhead of a new
  # cache load
  rnaseq-misc-step: &rnaseq-misc-step
      run:
        name: misc RNA-seq tests
        command: |
          ORIG=$(pwd)
          cd $DEPLOY
          source activate lcdb-wf-test

          # Check the help for test/lcdb-wf-test to see what args these
          # provide; some of them use the --until argument to restrict the
          # rules that are run. Note the use of --orig $ORIG to use the test
          # configs from the original clone rather than the deployed directory.
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --sra-pe          -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --sra-se          -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --strandedness-pe -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --star-2pass      -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --star-1pass      -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --pe              -k -r -p -j2 --use-conda --orig $ORIG



  # --------------------------------------------------------------------------
  # Standard colocalization workflow
  colocalization-step: &colocalization-step
      run:
        name: colocalization workflow
        command: |
          cd $DEPLOY/workflows/colocalization
          source activate lcdb-wf-test
          ./run_test.sh -j 1 --use-conda -j2 -k -p -r

# --------------------------------------------------------------------------
# Syntax note: All of the steps above, with their "&step-name" labels, can be
# referred to by a corresponding "*step-name" below. The "<<: *defaults"
# construct is a similar mechanism (YAML anchor) but extends rather than just
# referencing.  https://blog.daemonl.com/2016/02/yaml.html has a nice
# description of the difference.
#
# Here we define jobs as multiple steps by composing what we have defined
# above. These will show up as nodes in the CircleCI workflow DAG.
jobs:

  # This is the only job in which the cache is created. It also blocks all
  # other jobs until it's complete (it is a dependency of all other jobs,
  # configured in the workflows in the last section of this config).
  initial-setup:
    <<: *defaults
    steps:
      - checkout
      - *set-path

      # Check the hashes of requirements files. If they match a cache, load it.
      # The cache is set up to be the entire miniconda installation, so that
      # includes the lcdb-wf-test environment.
      #
      # If the hashes do not match the cache, then nothing is loaded and we do
      # not have the lcdb-wf-test environment.
      - *restore_cache

      # This step checks to see if lcdb-wf-test environment exists. Since the
      # only way it could get there at this point is by loading the cache, if
      # it's present then do nothing. Otherwise re-build the environments
      - *setup

      # When done, save the entire miniconda directory to the cache. Since
      # nothing else will run until this job is complete, we ensure that
      # subsequent jobs can load the latest cache without needing to rebuild it
      # themselves.
      - *save_cache

      - store_artifacts:
          path: /tmp/lcdb-wf-test/env.yaml
      - store_artifacts:
          path: /tmp/lcdb-wf-test/env-r.yaml
  pytest:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *setup
      - *pytest-step

  chipseq:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *chipseq-step
      - store_artifacts:
          path: /tmp/lcdb-wf-test/workflows/chipseq/data/chipseq_aggregation/multiqc.html

  chipseq-misc:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *chipseq-misc-step

  rnaseq:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *rnaseq-step
      - store_artifacts:
          path: /tmp/lcdb-wf-test/workflows/rnaseq/downstream.tar.gz
      - store_artifacts:
          path: /tmp/lcdb-wf-test/workflows/rnaseq/downstream/rnaseq.html
      - store_artifacts:
          path: /tmp/lcdb-wf-test/workflows/rnaseq/data/rnaseq_aggregation/multiqc.html

  rnaseq-misc:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *rnaseq-misc-step

  colocalization:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *colocalization-step

  references:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *references-step

  build-docs:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - run:
          name: Install sphinx
          command: source activate lcdb-wf-test && conda install -y sphinx make yaml
      - run:
          name: OK for unknown github host
          command: mkdir -p ~/.ssh/ && echo -e "Host github.com\n\tStrictHostKeyChecking no\n" > ~/.ssh/config
      - add_ssh_keys:
          fingerprints:
            - 2d:0c:b4:27:44:cf:f4:50:cc:14:a4:2b:c2:3c:09:06
      - run:
          name: Build and upload docs
          command: source activate lcdb-wf-test && ci/build-docs.sh
      - store_artifacts:
          path: /tmp/docs.tar.gz

  report-env:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - run:
          name: Report environment
          command: |
            conda env export -n lcdb-wf-test > /tmp/env.yaml
            cat /tmp/env.yaml
            conda env export -n lcdb-wf-test-r > /tmp/env-r.yaml
      - store_artifacts:
          path: /tmp/env.yaml
      - store_artifacts:
          path: /tmp/env-r.yaml

# ----------------------------------------------------------------------------
# This section configures the dependencies across jobs.
workflows:
  version: 2
  test-suite:
    jobs:
      - initial-setup
#      - pytest:
#         requires:
#           - initial-setup
#      - chipseq:
#         requires:
#           - initial-setup
#           - pytest
      - chipseq-misc:
         requires:
           - initial-setup
#           - pytest
#      - rnaseq:
#          requires:
#            - initial-setup
#            - pytest
#      - rnaseq-misc:
#          requires:
#            - initial-setup
#            - pytest
#      - references:
#          requires:
#            - initial-setup
#            - pytest
#      - colocalization:
#          requires:
#            - initial-setup
#            - pytest
#      - build-docs:
#          requires:
#            - initial-setup
#      - report-env:
#          requires:
#            - rnaseq
#            - rnaseq-misc
#            - chipseq
#            - chipseq-misc
#            - references
#            - colocalization

version: 2

variables:

  # default settings for all steps
  defaults: &defaults
    docker:
      - image: ubuntu:20.04

  # --------------------------------------------------------------------------
  # The caching dramatically speeds up testing time, because we can do the
  # time-consuming step of conda environment creation once and then use that
  # for subsequent steps. It works like this:
  #
  # The `initial-setup` job (defined in workflows below) saves the cache when
  # it's done. Here the cache is the miniconda directory. Later jobs
  # (chipseq-step, rnaseq-step, etc) restore that cache to dramatically speed
  # up testing time.
  #
  # The cache key is set to only re-make the cache when the relevant files
  # change. There's also a `v1-` prefix. This should be changed once in a while
  # just to re-trigger an environment rebuild (say, when some critical updates
  # hit bioconda).
  #
  # See https://circleci.com/docs/2.0/caching for details.

  save_cache: &save_cache
    save_cache:
      key: v5-{{ checksum "env.yml" }}-{{ checksum "env-r.yml" }}
      paths:
        - /opt/mambaforge

        # this file is created by sra-tools upon installation by conda, and so
        # needs to be included in the cache otherwise fastq-dump thinks it's
        # mis-configured.
        - /root/.ncbi/user-settings.mkfg

  restore_cache: &restore_cache
    restore_cache:
      keys:
        - v5-{{ checksum "env.yml" }}-{{ checksum "env-r.yml" }}

  # --------------------------------------------------------------------------
  # The path needs to be set each time; in jobs below this will be called as
  # one of the first steps in each job.
  set-path: &set-path
      run:
        name: Set path
        command: |
          # x11-utils required to avoid R::png() segfaulting
          apt update && apt install -y \
            curl \
            git \
            locales \
            locales-all \
            rsync \
            tree \
            wget \
            x11-utils

          # support en_US.utf8
          rm -rf /var/lib/apt/lists/*
          localedef -i en_US -c -f UTF-8 -A /usr/share/locale/locale.alias en_US.UTF-8

          # Set env vars to be used throughout; this is specific to how
          # circleci handles env vars.
          echo 'export DEPLOY=/tmp/lcdb-wf-test' >> $BASH_ENV
          echo 'export LCDBWF_ENV=lcdb-wf-test' >> $BASH_ENV
          echo 'export LCDBWF_ENV_R=lcdb-wf-test-r' >> $BASH_ENV
          echo 'export LC_ALL=en_US.utf8' >> $BASH_ENV
          echo 'export LANG=en_US.utf8' >> $BASH_ENV
          echo 'export ORIG=$(pwd)' >> $BASH_ENV

          # Note that if we don't escape \$PATH, we'll be stuck with the exact
          # PATH defined here, which will break anything needing conda envs.
          echo "export PATH=\$PATH:/opt/mambaforge/bin" >> $BASH_ENV
          source $BASH_ENV


  # --------------------------------------------------------------------------
  # Set up conda if the environments do not already exist
  setup: &setup
    run:
      name: Setup conda
      command: |
        source $BASH_ENV
        echo $PATH
        # /opt/mambaforge will only exist if there was a cache restore; otherwise we'll make it here.
        #
        # Use mambaforge which comes with mamba.
        if [ ! -e /opt/mambaforge ]; then
            curl -L https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh > mambaforge.sh
            bash mambaforge.sh -b -p /opt/mambaforge
            source "/opt/mambaforge/etc/profile.d/conda.sh"
            source "/opt/mambaforge/etc/profile.d/mamba.sh"
            conda activate

            which conda
            which mamba
            mamba --version

            # Note that mambaforge doesn't come with the defaults channel, but
            # we're adding it here at the beginning to simulate what most users
            # probably have locally (and following the bioconda docs). Using
            # strict channel priority means we should [theoretically] never
            # pull packages from defaults because they all exist on
            # conda-forge.
            conda config --system --add channels defaults

            conda config --system --add channels bioconda
            conda config --system --add channels conda-forge
            conda config --system --set channel_priority strict
            conda config --show

            # https://docs.conda.io/projects/conda-build/en/latest/resources/link-scripts.html,
            # post-link scripts should not depend on any installed or
            # to-be-installed conda packages...but they do.
            mamba install -n base r-base yq

            time mamba env create -n $LCDBWF_ENV --file env.yml
            time mamba env create -n $LCDBWF_ENV_R --file env-r.yml
        fi

  # --------------------------------------------------------------------------
  # Deploy into a new directory and get the test data.
  get-data: &get-data
    run:
      name: Download example data
      command: |
        source /opt/mambaforge/etc/profile.d/conda.sh
        conda activate $LCDBWF_ENV
        conda info --envs
        conda config --show

        # Copy the deploy script to a different location to simulate the
        # suggested deployment method of downloading just the script.
        cp deploy.py /tmp/deploy.py
        cd /tmp/

        # Deploy to the new directory, so we are testing the real-world case of post-deployment.
        # Note that $DEPLOY is set in the "set-paths" step configured above.
        python deploy.py --flavor full --dest $DEPLOY --branch $CIRCLE_BRANCH --clone

        set -x
        tree $DEPLOY
        tree $ORIG
        set +x

        # Separately copy over some test-specific files
        cp $ORIG/workflows/chipseq/run_test.sh $DEPLOY/workflows/chipseq/run_test.sh
        cp $ORIG/workflows/rnaseq/run_test.sh $DEPLOY/workflows/rnaseq/run_test.sh
        cp $ORIG/workflows/rnaseq/run_downstream_test.sh $DEPLOY/workflows/rnaseq/run_downstream_test.sh
        cp $ORIG/workflows/references/run_test.sh $DEPLOY/workflows/references/run_test.sh
        cp $ORIG/workflows/colocalization/run_test.sh $DEPLOY/workflows/colocalization/run_test.sh
        cp $ORIG/workflows/variant-calling/run_test.sh $DEPLOY/workflows/variant-calling/run_test.sh

        mkdir $DEPLOY/ci
        mkdir $DEPLOY/test
        cp $ORIG/test/lcdb-wf-test $DEPLOY/test/lcdb-wf-test
        cp $ORIG/test/workflow_test_params.yaml $DEPLOY/test/workflow_test_params.yaml
        cp $ORIG/ci/get-data.py $DEPLOY/ci/get-data.py

        # the ./run_test.sh scripts run this
        cp $ORIG/ci/preprocessor.py $DEPLOY/ci/preprocessor.py

        # download example data
        cd $DEPLOY
        test/lcdb-wf-test data --kind=all --verbose

  # --------------------------------------------------------------------------
  # Run the doctests across the included modules
  pytest-step: &pytest-step
    run:
      name: Run pytest suite and testthat suite
      command: |
        source /opt/mambaforge/etc/profile.d/conda.sh
        conda activate $LCDBWF_ENV
        # run unit tests and doctests for the modules in lib
        test/lcdb-wf-test unit_tests --pytest

        # Ensure that the chunks in rnaseq.Rmd have matching documentation
        test/lcdb-wf-test unit_tests --ensure-docs

        # find all URLs in reference configs and make sure they exist
        test/lcdb-wf-test unit_tests --url-check

        # run R package unit tests using the R env
        test/lcdb-wf-test unit_tests --r-test


  # --------------------------------------------------------------------------
  # Standard chipseq workflow
  chipseq-step: &chipseq-step
      run:
        name: chipseq workflow
        command: |
          cd $DEPLOY/workflows/chipseq
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV
          $DEPLOY/test/lcdb-wf-test chipseq --run-workflow --use-conda -j2 -k -p -r
          $DEPLOY/test/lcdb-wf-test chipseq --trackhub

  # --------------------------------------------------------------------------
  # Previous versions had an error where chipseq peaks needed to be defined for
  # every caller. This does a (relatively) quick test to only run a single
  # sample through a single peak-caller to prevent regression of that error
  chipseq-misc-step: &chipseq-misc-step
      run:
        name: chipseq misc
        command: |
          cd $DEPLOY/workflows/chipseq
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV

          ./run_test.sh --use-conda -j2 -k -p -r \
            --configfile $ORIG/test/test_configs/test_chipseq_regression.yaml \
            --config sampletable=$ORIG/test/test_configs/chipseq_one_run.tsv \
            merged_bigwigs="{}" \
            --until bed_to_bigbed

          # Piggy-backing on that test, here we check to make sure it's OK to
          # omit peak-calling config. We just do a dry-run.
          #
          # NOTE: this fails in recent versions of Snakemake, see
          # https://github.com/snakemake/snakemake/issues/1815. Disabling the
          # test for now...
          if false; then
            ./run_test.sh -n \
              --configfile $ORIG/test/test_configs/test_chipseq_no_peaks.yaml \
              --config sampletable=$ORIG/test/test_configs/chipseq_one_run.tsv \
              merged_bigwigs="{}" \
              --until bed_to_bigbed
          fi

  # --------------------------------------------------------------------------
  # Standard references workflow.
  references-step: &references-step
      run:
        name: references workflow
        command: |
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV
          # RNA-seq/ChIP-seq references
          $DEPLOY/test/lcdb-wf-test references --run-workflow --configfile=config/config.yaml -j2 -p -r -k --orig $ORIG

          # Variant-calling references
          $DEPLOY/test/lcdb-wf-test references --run-workflow --configfile=$ORIG/test/test_configs/variant-calling.yaml -j2 -p -r -k --orig $ORIG



  # --------------------------------------------------------------------------
  # Standard RNA-seq workflow
  rnaseq-step: &rnaseq-step
      run:
        name: rnaseq workflow
        command: |
          cd $DEPLOY
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow -n
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --use-conda -j2 -k -p -r --orig $ORIG

          $DEPLOY/test/lcdb-wf-test rnaseq --trackhub --orig $ORIG

          # This run the preprocessor on the Rmd files and stores them
          # in a new download-test directory (see the comments in the script
          # for details)
          $DEPLOY/test/lcdb-wf-test rnaseq --downstream

          # bundle up the entire directory to be used as an artifact
          tar -zcf /tmp/downstream.tar.gz workflows/rnaseq/downstream-test/
          cp workflows/rnaseq/downstream-test/rnaseq.html /tmp/rnaseq.html
          cp workflows/rnaseq/downstream-test/functional-enrichment.html /tmp/functional-enrichment.html
          cp workflows/rnaseq/downstream-test/gene-patterns.html /tmp/gene-patterns.html
          cp workflows/rnaseq/data/rnaseq_aggregation/multiqc.html /tmp/rnaseq.html

  # --------------------------------------------------------------------------
  # Various tests on RNA-seq workflow that don't warrant the overhead of a new
  # cache load
  rnaseq-misc-step: &rnaseq-misc-step
      run:
        name: misc RNA-seq tests
        command: |
          ORIG=$(pwd)
          cd $DEPLOY
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV

          # Check the help for test/lcdb-wf-test to see what args these
          # provide; some of them use the --until argument to restrict the
          # rules that are run. Note the use of --orig $ORIG to use the test
          # configs from the original clone rather than the deployed directory.
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --sra-pe          -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --sra-se          -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --strandedness-pe -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --star-2pass      -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --star-1pass      -k -r -p -j2 --use-conda --orig $ORIG
          $DEPLOY/test/lcdb-wf-test rnaseq --run-workflow --pe              -k -r -p -j2 --use-conda --orig $ORIG



  # --------------------------------------------------------------------------
  # Standard colocalization workflow
  colocalization-step: &colocalization-step
      run:
        name: colocalization workflow
        command: |
          cd $DEPLOY/workflows/colocalization
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV
          $DEPLOY/test/lcdb-wf-test colocalization --run-workflow -k -r -p -j2 --use-conda --orig $ORIG


  # --------------------------------------------------------------------------
  # Variant-calling workflow
  variantcalling-step: &variantcalling-step
      run:
        name: variantcalling workflow
        command: |
          cd $DEPLOY
          source /opt/mambaforge/etc/profile.d/conda.sh
          conda activate $LCDBWF_ENV
          $DEPLOY/test/lcdb-wf-test variantcalling --run-workflow -n
          $DEPLOY/test/lcdb-wf-test variantcalling --run-workflow --use-conda -j2

          tar -zcf /tmp/variantcalling.tar.gz workflows/variant-calling/results

# --------------------------------------------------------------------------
# Syntax note: All of the steps above, with their "&step-name" labels, can be
# referred to by a corresponding "*step-name" below. The "<<: *defaults"
# construct is a similar mechanism (YAML anchor) but extends rather than just
# referencing.  https://blog.daemonl.com/2016/02/yaml.html has a nice
# description of the difference.
#
# Here we define jobs as multiple steps by composing what we have defined
# above. These will show up as nodes in the CircleCI workflow DAG.
jobs:

  # This is the only job in which the cache is created. It also blocks all
  # other jobs until it's complete (it is a dependency of all other jobs,
  # configured in the workflows in the last section of this config).
  initial-setup:
    <<: *defaults
    steps:
      - checkout
      - *set-path

      # Check the hashes of requirements files. If they match a cache, load it.
      # The cache is set up to be the entire miniconda installation, so that
      # includes the lcdb-wf-test environment.
      #
      # If the hashes do not match the cache, then nothing is loaded and we do
      # not have the lcdb-wf-test environment.
      - *restore_cache

      # This step checks to see if lcdb-wf-test environment exists. Since the
      # only way it could get there at this point is by loading the cache, if
      # it's present then do nothing. Otherwise re-build the environments
      - *setup

      # When done, save the entire miniconda directory to the cache. Since
      # nothing else will run until this job is complete, we ensure that
      # subsequent jobs can load the latest cache without needing to rebuild it
      # themselves.
      - *save_cache

      - store_artifacts:
          path: /tmp/lcdb-wf-test/env.yaml
      - store_artifacts:
          path: /tmp/lcdb-wf-test/env-r.yaml
  pytest:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *setup
      - *pytest-step

  chipseq:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *chipseq-step
      - store_artifacts:
          path: /tmp/lcdb-wf-test/workflows/chipseq/data/chipseq_aggregation/multiqc.html

  chipseq-misc:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *chipseq-misc-step

  rnaseq:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *rnaseq-step
      - store_artifacts:
          path: /tmp/downstream.tar.gz
          destination: downstream.tar.gz
      - store_artifacts:
          path: /tmp/rnaseq.html
          destination: rnaseq.html
      - store_artifacts:
          path: /tmp/multiqc.html
          destination: multiqc.html
      - store_artifacts:
          path: /tmp/functional-enrichment.html
          destination: functional-enrichment.html
      - store_artifacts:
          path: /tmp/gene-patterns.html
          destination: gene-patterns.html


  variantcalling:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *variantcalling-step
      - store_artifacts:
          path: /tmp/variantcalling.tar.gz
          destination: variantcalling.tar.gz

  rnaseq-misc:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *rnaseq-misc-step

  colocalization:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *colocalization-step

  references:
    <<: *defaults
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - *get-data
      - *references-step

  build-docs:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - run:
          name: Install sphinx
          command: |
            source /opt/mambaforge/etc/profile.d/conda.sh
            conda activate lcdb-wf-test
            mamba install -y sphinx make yaml
      - run:
          name: OK for unknown github host
          command: mkdir -p ~/.ssh/ && echo -e "Host github.com\n\tStrictHostKeyChecking no\n" > ~/.ssh/config
      - add_ssh_keys:
          fingerprints:
            - 2d:0c:b4:27:44:cf:f4:50:cc:14:a4:2b:c2:3c:09:06
      - run:
          name: Build and upload docs
          command: |
            source /opt/mambaforge/etc/profile.d/conda.sh
            conda activate lcdb-wf-test
            ci/build-docs.sh
      - store_artifacts:
          path: /tmp/docs.tar.gz

  report-env:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - *restore_cache
      - *set-path
      - run:
          name: Report environment
          command: |
            source /opt/mambaforge/etc/profile.d/conda.sh
            conda env export -n lcdb-wf-test > /tmp/env.yaml
            conda env export -n lcdb-wf-test-r > /tmp/env-r.yaml
      - store_artifacts:
          path: /tmp/env.yaml
      - store_artifacts:
          path: /tmp/env-r.yaml

# ----------------------------------------------------------------------------
# This section configures the dependencies across jobs.
workflows:
  version: 2
  test-suite:
    jobs:
      - initial-setup
      - pytest:
         requires:
           - initial-setup
      - chipseq:
         requires:
           - initial-setup
           - pytest
      - chipseq-misc:
         requires:
           - initial-setup
           - pytest
      - rnaseq:
          requires:
            - initial-setup
            - pytest
      - rnaseq-misc:
          requires:
            - initial-setup
            - pytest
      - references:
         requires:
           - initial-setup
           - pytest
      - colocalization:
          requires:
            - initial-setup
            - pytest
      - variantcalling:
         requires:
           - initial-setup
      - build-docs:
          requires:
            - initial-setup
      - report-env:
          requires:
            - rnaseq
            - rnaseq-misc
            - chipseq
            - chipseq-misc
          # - references
            - colocalization
            - variantcalling

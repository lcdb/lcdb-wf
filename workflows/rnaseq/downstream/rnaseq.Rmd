
```{r, include=FALSE}
# =============================================================================
# IMPORTANT:
# Before running this, search for the string "Assumption". This indicates parts
# of the file that need to be changed depending on the experiment.
# =============================================================================
#
# This Rmd file aims to include "the works", with some preliminary exploratory
# visualizations, followed by differential expression using both gene models
# and transcript models (with examples of interaction) SVA, and some downstream
# GO analysis.
#
# Assumptions are indicated where they are made, so look for those comments
# starting with "Assumptions:" identify places that may need some editing.
# Notably, the only model run by default is `~group`, which will only be
# appropriate for the simplest experiments.

# There are a fair amount of helper functions. They are stored in
# `helpers.Rmd`, and included here as a child document so that all code is
# self-contained in the HTML rendered from this RMarkdown.
#-----------------------------------------------------------------------------
```

```{r, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, warning=FALSE, message=FALSE,
                      bootstrap.show.code=FALSE, bootstrap.show.output=FALSE,

                      # try disabling this when running locally for nicer figures
                      #dev='bitmap',

                      fig.ext='png')
```
# RNA-seq results

```{r, include=FALSE}
# Here's a template for including a link that will load a prepared track hub. Not included by default.
# [Load hub and prepared session on UCSC Genome Browser](http://genome.ucsc.edu/cgi-bin/hgTracks?db=ASSEMBLY&hubUrl=https://HOST/PATH/hub.txt&hgS_loadUrlName=https://HOST/PATH/session.txt&hgS_doLoadUrl=submit&position=chr1:1-100)
```

Note: if you're unfamiliar with any of the plots or tables here, see the
[Background and help](#Help) section for details.


```{r imports}
library(DESeq2)
library(gridExtra)
library(ggplot2)
library(genefilter)
library(readr)
library(tximport)
library(clusterProfiler)
library(AnnotationHub)
library(BiocParallel)
library(UpSetR)
```

```{r child='helpers.Rmd'}
# When running interactively, use the following to load helper functions.
# When rendering this file, the contents of this code block will be skipped
# since it is a "child" block for which all contents are expected to be
# in the other file.
rmarkdown::render('helpers.Rmd', run_pandoc=FALSE)
```

```{r annotationhub_setup}
# Try disabling this when running locally to get nicer figures:
# options(bitmapType='cairo')

# Assumption: change these to reflect organism you're working with.
# e.g., 'Mus musculus', 'mmu'; 'Homo sapiens', 'hsa'. Provide an annotation key
# to override if you know the one to use, otherwise leave NA.
annotation_genus_species <- 'Drosophila melanogaster'
kegg.org <- 'dme'
hub.cache <- '../../../include/AnnotationHubCache'
annotation_key_override <- NA

# To ensure that we do not clobber any local copies of the annotation, we copy
# to tmp. This also should increase performance when running on the cluster --
# we avoid poor sqlite performance on shared filesystems by copying to
# local scratch space.
file.copy(hub.cache, tempdir(), recursive=TRUE)
new.cache <- file.path(tempdir(), 'AnnotationHubCache')

orgdb <- get.orgdb(
    annotation_genus_species,
    cache=new.cache,
    annotation_key_override=annotation_key_override
)
```

```{r coldata_setup}
# Assumption: path name to sampletable
sample.table.filename = '../config/sampletable.tsv'

colData <- read.table(sample.table.filename, sep='\t', header=TRUE)

# Assumption: which featureCounts strandedness to use. All three are created by
# default; here is where you specify which one to use for differential
# expression.

featurecounts.strandedness <- 's0'  # unstranded
# featurecounts.strandedness <- 's1' # plus-strand reads correspond to sense-strand transcription (e.g., Ovation kits)
# featurecounts.strandedness <- 's2' # minus-strand reads correspond to sense-strand transcription (e.g., TruSeq kits)

# Assumption: data directory and extension to featurecounts output
colData$featurecounts.path <- sapply(
    colData$samplename,
    function (x) file.path(
        '..', 'data', 'rnaseq_samples', x,
        paste0(x, '.cutadapt.bam.featurecounts.', featurecounts.strandedness, '.txt')
        )
    )

# Assumption: data directory and salmon filenames
colData$salmon.path <- sapply(
    colData$samplename,
    function (x) file.path('..', 'data', 'rnaseq_samples', x, paste0(x, '.salmon'), 'quant.sf')
)

# Assumption: which columns in sampletable, and that "group" should be factor
factor.columns <- c('group')
exclude.for.printing <- c('featurecounts.path', 'salmon.path', 'orig_filename')
for (col in factor.columns){
    colData[[col]] <- as.factor(colData[[col]])
}

# Assumption: "control" is the base level for the group factor
colData$group <- relevel(colData$group, ref='control')
```
## Experiment overview

Here is the sample table with metadata used for this analysis:

```{r}
knitr::kable(colData[, colnames(colData)[!colnames(colData) %in% exclude.for.printing]])
```

```{r ddstxi, cache=TRUE, eval=TRUE}
# Assumption: eval=TRUE by default, for testing.
# Change to eval to FALSE to disable in practice.

# Load transcript-level counts
dds.txi <- DESeqDataSetFromSalmon(
                                  sampleTable=colData,
                                  directory='.',
                                  # Assumption: what to model
                                  design=~group)
# rlog normalize transcript counts
rld.txi <- varianceStabilizingTransformation(dds.txi, blind=FALSE)
```


```{r dds_initial, cache=TRUE}
# Load gene-level counts
dds <- DESeqDataSetFromFeatureCounts(
    sampleTable=colData,
    directory='.',
    # Assumption: what to model.
    # Used for EDA, so it's recommended to use a single factor that describes
    #condition
    design=~group)

# Assumption: If gene names came in as Ensembl "gene.version" IDs, here we
# split them to only give the gene ID.
rownames(dds) <- sapply(strsplit(rownames(dds), '.', fixed=TRUE), function (x) x[1])

# Variance-stablilized transform to normalize gene-level counts.
# Alternatively, use `rlog`, but that gives about the same results
# and is slow for large numbers of samples.
#
# Since this is for exploratory data analysis, we use blind=TRUE
# to ignore the design.
rld <- varianceStabilizingTransformation(dds, blind=TRUE)
```

## Sample clustering and QC

The following heatmap shows a hierarchical clustering of pairwise distances
between samples. Darker blue means less distant (i.e. more similar). In general
we expect to see replicates clustering together and separation of treatments.

## Clustered heatmap

```{r}
plot.heatmap(rld, colData, c('group'))
```

## PCA

Another way of looking at sample clustering is principal components analysis
(PCA). The x- and y-axes do not have units, rather, they represent the
dimensions along which the samples vary the most. The amount of variance
explained by each principal component is indicated in the axes label.


```{r}
# Assumption: gene-level counts
# Assumption: color by 'group' factor
plotPCA(rld, intgroup=c('group'))
```


## Most-varying genes

We can also look at the most varying genes to get a sense of the clustering.
This heatmap takes the top 50 most-varying genes and plots their deviation from
the row mean.

```{r, fig.height=12}
vargenes.heatmap(rld, c('group'))
```

## Size factors
Size factors: ideally, all libraries were sequenced to identical depth, in
which case all size factors would be 1.0. In practice, this is almost never the
case. These size factor estimates are DESeq2's way of showing how sequencing
depth varies across libraries. If some libraries are much higher or lower than
1 then those libraries had dramatically different coverage and we should be
careful about interpreting results.

```{r}
dds <- estimateSizeFactors(dds)
sf <- sizeFactors(dds)
sf <- sf[order(sf)]
knitr::kable(sf)
```

```{r, eval=FALSE}
# Assumption: you do not want to use parallel.  If you do, change eval to
# TRUE and set cores appropriately. Then use the `parallel=TRUE` argument
# whenever you call the `DESeq()` function.
register(MulticoreParam(4))
```

```{r dds_models, cache=TRUE}
# Assumption: using gene counts.

dds <- DESeqDataSetFromFeatureCounts(
    sampleTable=colData,
    directory='.',
    # Assumption: model to use
    design=~group
)

# Assumption: If gene names came in as Ensembl "gene.version" IDs, here we
# split them to only give the gene ID.
rownames(dds) <- sapply(strsplit(rownames(dds), '.', fixed=TRUE), function (x) x[1])
dds <- DESeq(dds,
    # Assumption: this the default for versions of DESeq2 > 1.16. We set it
    # explicitly here for consistency.
    betaPrior=FALSE)
```



```{r results, cache=TRUE}
# Assumption: use only one run, and the contrast you want is group
# (treatment/control).
#
# Assumption: you want the lfcShrink version of the results. In DESeq2 versions
# >1.16, the lfc shrinkage is performed in a separate step, so that's what we do here.
# This is slightly different results than if you used betaPrior=TRUE when
# creating the DESeq object.
#
# By adding more results to res.list (and its originating dds to ddd.list), you
# will get DE results sections automatically created for each item. The
# res.list.lookup maps the list names to nicer labels that will be used in
# headings.

# As currently implemented (05 apr 2018), lfcShrink checks its arguments for an existing results
# table. If it exists, it applies shrinkage to the lfc and se in that table. If it ~doesn't~ exist,
# it calls results on dds with the syntax
#
## res <- results(dds, name=coef)
# or
## res <- results(dds, contrast=contrast)
#
# It does not pass any further arguments to results, and it doesn't warn you that results-style arguments
# were unrecognized and ignored. Therefore, lfcShrink does not directly support
# lfcThreshold, or other alternative hypotheses, or any of the custom analysis methods you can access
# through results. To get those, you have to call results first, without shrinkage, and then apply lfcShrink.

res.lfcthresh.2 <- results(dds, contrast=c('group', 'treatment', 'control'), lfcThreshold=2)

res.list <- list(
                 all=lfcShrink(dds, contrast=c('group', 'treatment', 'control')),
                 lfc2=lfcShrink(dds, contrast=c('group', 'treatment', 'control'), res=res.lfcthresh.2)
                 )
dds.list <- list(
                 all=dds,
                 lfc2=dds
                 )

res.list.lookup <- list(
                        all='Using a log2 fold change threshold of 0',
                        lfc2='Using a log2 fold change threshold of 2'
                        )
```

```{r attach, cache=TRUE, depends='results'}
# Assumption: Original annotations use Ensembl IDs
keytype <- 'ENSEMBL'

# Assumption: Symbol, Uniprot and alias columns are available in the OrgDb
columns <- c('SYMBOL', 'UNIPROT', 'ALIAS')

for (name in names(res.list)){
    res.list[[name]] <- attach.info(
        res.list[[name]],
        keytype=keytype,
        columns=columns)
}
```

# Differential expression

Here is a table summarizing the comparisons. See the [Background and
help](#Help) section for details.

```{r, results='asis'}
# Summarize all experiments
knitr::kable(summarize.res.list(res.list, dds.list, res.list.lookup))
```

For each comparison, we report:

- the line from the summary table for this comparison
- counts plots for the top 3 up- and top 3 down-regulated genes
- an M-A plot
- a p-value histogram

See the [Background and help](#Help) section for details on these.

```{r, results='asis'}
# Assumption: which columns to add to the top plots' titles. These may have
# come from the `attach.info` call above.
add_cols <- c('symbol', 'alias')

for (name in names(res.list)){

  # NOTE: You might find it useful to call the `the.works()` function in
  # helpers.Rmd which does a lot of this in one shot.
  # the.works(name, res.list, dds.list, res.list.lookup, add_cols=add_cols)

  dds.i <- dds.list[[name]]
  res.i <- res.list[[name]]
  mdcat('## ', res.list.lookup[[name]])
  mdcat('### Summary of results')
  print(knitr::kable(my.summary(res.i, dds.i)))
  mdcat('### Normalized counts of top 3 upregulated genes')
  top.plots(padj.order(res.i), 3, my.counts, dds.i, add_cols)
  mdcat('### Normalized counts of top 3 downregulated genes')
  top.plots(padj.order(res.i, reverse=TRUE), 3, my.counts, dds.i, add_cols)
  mdcat('### M-A plot')
  plotMA(res.i)
  mdcat('### P-value distribution')
  pval.hist(res.i)
}
```


```{r, fig.width=12, results='asis'}
if (length(res.list) > 1){
    mdcat("## UpSet plots")
    mdcat("Gather together all the interesting gene sets into an ",
          "['UpSet' plot](http://caleydo.org/tools/upset/). These plots show ",
          "the combinatorial overlaps of genes found to be up, down, and any ",
          "changed across the different contrasts performed.")

    ll <- lapply(res.list, get.sig, 'up')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Upregulated UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }

    ll <- lapply(res.list, get.sig, 'down')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Downregulated UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }

    ll <- lapply(res.list, get.sig, 'changed')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Changed genes UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }
}
```

# Gene patterns

We can roughly group genes into expression patterns. This uses the [DEGreport
package](https://www.bioconductor.org/packages/release/bioc/html/DEGreport.html),
which in turn uses the
[ConsensusClusterPlus](https://www.bioconductor.org/packages/release/bioc/html/ConsensusClusterPlus.html)
algorithm to cluster genes into similar expression patterns. The lists of genes
found in each cluster are reported below the plot.

```{r, fig.width=12, results='asis', cache=TRUE}

ll <- lapply(res.list, get.sig, 'changed')
ll <- ll[lapply(ll, length) > 0]
for (name in names(ll)){
    genes <- ll[[name]]

    # Set a hard limit -- beware plotting more genes than this as it could take
    # a lot of time to perform the clustering. If there are more than this
    # limit, then take a random sample.
    lim <- 2000
    if (length(genes) > lim){
        genes <- sample(genes, lim)
    }
    idx <- rownames(rld) %in% genes
    ma <- assay(rld)[idx,]
    mdcat('## ', res.list.lookup[[name]])
    colData.i <- colData(dds.list[[name]])

    # Assumption:
    # - you want the gene patterns to be plotted across "group" on the
    #   x-axis (this is the `time` argument to degPatterns)
    # - min cluster size (minc) is 1. This is for testing purposes; you'll
    #   probably want to reset to at least the DEGreport default of 15.
    # - For more complicated designs, try the `col` argument to color by
    #   another factor.
    d <- degPatterns(ma, colData.i, time='group', reduce=TRUE, cutoff=0.5, minc=1)

    dir.create('final_clusters')
    for (u in unique(d$df$cluster)){
        fn <- file.path('final_clusters', paste0('final.', name, '.cluster.', u, '.txt'))
        write.table(d$df[d$df$cluster==u, 'genes'], file=fn, quote=FALSE, row.names=FALSE, col.names=FALSE)
        mdcat('- [', fn, '](', fn, '), cluster "', u, '" genes')
    }
}
```

# Exported results

```{r}
# Subset out up/down regulated. Other selections can be added, and
# corresponding output files will be created and GO analysis will be performed
# on them below.
#
# sel.list will be a list of lists of subsets of the original results in
# res.list; access selections with, e.g., sel.list[['experiment1]'][['up']]
sel.list <- list()
for (name in names(res.list)){
  res <- res.list[[name]]

  # Assumption: significance level
  alpha <- 0.1
  sel.list[[name]] <- list(
    up=res[(res$padj < alpha) & (res$log2FoldChange > 0) & !is.na(res$padj) & !is.na(res$log2FoldChange),],
    dn=res[(res$padj < alpha) & (res$log2FoldChange < 0) & !is.na(res$padj) & !is.na(res$log2FoldChange),]
  )
}
```

```{r, results='asis'}
# Write out files for full and each selection, and create a link to them in the
# HTML generated by this RMarkdown.
for (name in names(res.list)){
  mdcat('## ', res.list.lookup[[name]])
  fn <- paste0(name, '.tsv')
  write.table(res.list[[name]], file=fn, row.names=FALSE, sep='\t')
  mdcat('- [', fn, '](', fn, '), results for ', res.list.lookup[[name]])
  for (sel in names(sel.list[[name]])){
    fn <- paste0(name, '.', sel, '.tsv')
    write.table(sel.list[[name]][[sel]], file=fn, row.names=FALSE, sep='\t')
    mdcat('- [', fn, '](', fn, '), just the "', sel, '" genes for ', res.list.lookup[[name]])
  }
}
```

# Gene ontology and KEGG pathway enrichment

Here we perform gene ontology enrichment and KEGG pathway enrichment using the
[clusterProfiler](https://bioconductor.org/packages/release/bioc/vignettes/clusterProfiler/inst/doc/clusterProfiler.html)
package with some custom plotting functions.


```{r GO, cache=TRUE}
# Here we summarize the results into dataframes and attach additional
# information to them such that they can be concatenated together into a large
# tidy dataframe.
universe <- names(dds)
enrich.list <- list()
for (name in names(sel.list)){
  for (sel in names(sel.list[[name]])){
    sel.res <- sel.list[[name]][[sel]]

    # GO enrichment
    go.label <- paste(name, sel, 'go', sep='.')
    message(paste(go.label, '...'))
    sg <- summarize.go(
      clusterprofiler.enrichgo(sel.res$gene, universe, orgdb),
      list(label=go.label, sel=sel, experiment=name))
    if (!is.null(sg)){
      enrich.list[[go.label]] <- sg
    }

    # KEGG enrichment
    kegg.label <- paste(name, sel, 'kegg', sep='.')
    message(paste(kegg.label, '...'))
    sk <- summarize.kegg(
      clusterprofiler.enrichkegg(sel.res$uniprot, kegg.org),
      list(label=kegg.label, sel=sel, experiment=name))
    if (!is.null(sk)){
      enrich.list[[kegg.label]] <- sk
    }
  }
}
```

These plots show:

- enriched category (y-axis)
- magnitude of enrichment (x-axis; plotted as -10 log10 (FDR) or "phred" scale)
- fraction of regulated genes falling within a particular category (size)
- experiment (color)
- ontology (sub-panels; BP=biological process, MF=molecular function,
  CC=cellular component, kegg=KEGG pathway)
- direction of regulation (up- or downregulated; separate figures; labeled at the top)

The plots show the top 50 terms, and are sorted by the max enrichment across
experiments.

```{r fullenrich, cache=TRUE}
full.enrich.table <- do.call(rbind, enrich.list)
write.table(full.enrich.table, file='functional_enrichment.tsv', row.names=FALSE, sep='\t')
```

The full analysis table can be viewed here:

- [functional_enrichment.tsv](functional_enrichment.tsv)

```{r, go, fig.height=15, fig.width=15, dev=c('pdf', 'png')}
# While clusterProfiler has canned figures, it's difficult to customize them.
# Instead, here we create a tidy dataframe of all experiments, directions, and
# enrichment analyses so that we can plot them with ggplot2 however the
# experiment dictates


lim <- 50
nchunks <- 1

# Assumption: all experiments have the same selections
for (sel in names(sel.list[[1]])){
  mdcat('## ', sel)
  m <- do.call(rbind, enrich.list)

  ###compute description length distribution for entire ontology
  length.quantile <- quantile(nchar(as.vector(m$Description, mode="character")), 0.75)

  # convert to phred score, and flip the "downregulated"
  m$phred <- -10 * log10(m$p.adjust)
  idx <- m$sel == sel

  m <- m[idx,]

  if (nrow(m) == 0){next}

  #replace ontology descriptions with truncations to make plot prettier
  temp.desc <- as.vector(m$Description, mode="character")
  needs.replacement <- which(nchar(temp.desc) > length.quantile)
  temp.desc <- strtrim(temp.desc, length.quantile)
  temp.desc[needs.replacement] <- paste(temp.desc[needs.replacement], "...", sep="")
  m$Description <- factor(temp.desc)

  # Grab the top (ordered by phred)
  max.per.term <- aggregate(phred~Description, m, FUN=max)
  o <- rev(order(max.per.term$phred))
  m$Description <- factor(m$Description, levels=rev(max.per.term$Description[o]))
  top.terms <- (max.per.term$Description[o][seq(lim)])
  m.sub <- m[m$Description %in% top.terms,]
  m.sub$Description <- droplevels(m.sub$Description)
  levels(m.sub$Description) <- max.per.term$Description[o]
  #m.sub <- m.sub[order(m.sub$Description),]

  chunksize <- ceiling(lim / nchunks)
  lookup <- rep(1:nchunks, each=chunksize)
  m.sub$chunk <- 0
  for (i in seq(length(lookup))){
    term <- as.character(top.terms[i])
    lab <- lookup[i]
    m.sub$chunk[m.sub$Description == term] = lab
  }


print(ggplot(m.sub) +
    geom_point(alpha=0.6) +
    aes(y=Description, x=phred, size=frac, color=experiment) +
    theme(text=element_text(size=12)) +
    facet_grid(ontology~sel, scales='free_y', space='free_y')
  )
}
```

# Session info
For reproducibility purposes, here is the output of `sessionInfo()` showing the
versions of all packages used here.

```{r, collapse=FALSE}
sessionInfo()
```

# Help

```{r, child="help_docs.Rmd", run_pandoc=FALSE}
```

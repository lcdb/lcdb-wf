import sys
import os
import yaml
import pandas as pd

sys.path.insert(0, os.path.dirname(workflow.snakefile) + "/../..")
from lib import utils


configfile: "config/config.yaml"


REFERENCES = config.get("reference_dir", "../../references")
sampletable = pd.read_table(config["sampletable"], sep="\t", comment="#")
sampletable = sampletable.set_index(sampletable.columns[0], drop=False)
is_paired = utils.detect_layout(sampletable) == "PE"
n = ["1", "2"] if is_paired else ["1"]
SAMPLES = sampletable.index


wildcard_constraints:
    n="[1,2]",
    sample="|".join(SAMPLES),


localrules:
    symlinks,
    symlink_targets,


rule all:
    input:
        "data/rnaseq_aggregation/multiqc.html",


include: "../references/Snakefile"

# Optionally run `snakemake strand_check` to do a preliminary run on
# automatically-subset data to evaluate strandedness.
include: "strand_check.smk"

# If the sampletable is from SRA, handle it here.
include: "sra.smk"


rule symlinks:
    input:
        lambda wc: (
            sampletable.loc[wc.sample, ["orig_filename", "orig_filename_R2"]]
            if is_paired
            else sampletable.loc[wc.sample, ["orig_filename"]]
        ),
    output:
        expand("data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.fastq.gz", n=n),
    threads: 1
    resources:
        mem="1g",
        runtime="10m",
    run:
        assert len(output) == len(input), (input, output)
        for src, linkname in zip(input, output):
            utils.make_relative_symlink(src, linkname)


rule symlink_targets:
    input:
        expand(
            "data/rnaseq_samples/{sample}/{sample}_R{n}.fastq.gz", sample=SAMPLES, n=n
        ),



rule cutadapt:
    input:
        fastq=expand("data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.fastq.gz", n=n),
    output:
        fastq=expand(
            "data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.cutadapt.fastq.gz", n=n
        ),
    log:
        "data/rnaseq_samples/{sample}/{sample}_cutadapt.fastq.gz.log",
    threads: 6
    resources:
        mem="2g",
        runtime="2h",
    run:
        if is_paired:
            shell(
                "cutadapt "
                "-o {output[0]} "
                "-p {output[1]} "
                "-j {threads} "
                "--nextseq-trim 20 "
                "--overlap 6 "
                "--minimum-length 25 "
                "-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA "
                "-A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT "
                "{params.extra} "
                "{input.fastq[0]} "
                "{input.fastq[1]} "
                "&> {log}"
            )
        else:
            shell(
                "cutadapt "
                "-o {output[0]} "
                "-j {threads} "
                "--nextseq-trim 20 "
                "--overlap 6 "
                "--minimum-length 25 "
                "-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA "
                "{params.extra} "
                "{input.fastq[0]} "
                "&> {log}"
            )


rule fastqc:
    input:
        "data/rnaseq_samples/{sample}/{sample}{suffix}",
    threads: 1
    output:
        html="data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.html",
        zip="data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.zip",
    resources:
        mem="8g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.log",
    run:
        outdir = os.path.dirname(output.html) or "."
        shell(
            "fastqc "
            "--noextract "
            "--quiet "
            "--outdir {outdir} "
            "{input} "
            "2> {log} "
        )
        outfile = os.path.basename(input[0])
        for s in [".fastq", ".fq", ".gz", ".bam"]:
            outfile = outfile.replace(s, "")
        out_zip = os.path.join(outdir, outfile + "_fastqc.zip")
        if not os.path.abspath(out_zip) == os.path.abspath(output.zip):
            shell("mv {out_zip} {output.zip}")
        out_html = os.path.join(outdir, outfile + "_fastqc.html")
        if not os.path.abspath(out_html) == os.path.abspath(output.html):
            shell("mv {out_html} {output.html}")



rule star:
    "Align with STAR (1-pass mode)"
    input:
        fastq=rules.cutadapt.output,
        index=rules.star_index.output,
        annotation=f"{REFERENCES}/annotation.gtf",
    output:
        bam=temporary("data/rnaseq_samples/{sample}/{sample}.cutadapt.bam"),
        sjout=temporary(
            "data/rnaseq_samples/{sample}/{sample}.cutadapt.star.SJ.out.tab"
        ),
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.log",
    threads: 16
    resources:
        mem="64g",
        runtime="8h",
        disk="80g",
    run:
        genomedir = os.path.dirname(input.index[0])
        outdir = os.path.dirname(output[0])
        prefix = output.bam.replace(".bam", ".star.")
        if os.getenv("TMPDIR"):
            tmpdir_arg = "--outTmpDir $TMPDIR/star "
        else:
            tmpdir_arg = ""
        shell(
            "STAR "
            "--runThreadN {threads} "
            "--genomeDir {genomedir} "
            "--readFilesIn {input.fastq} "
            "--readFilesCommand zcat "
            "--outFileNamePrefix {prefix} "
            "{tmpdir_arg} "
            "--outSAMtype BAM SortedByCoordinate "
            "--outStd BAM_SortedByCoordinate > {output.bam} "

            # NOTE: The STAR docs indicate that the following parameters are
            # standard options for ENCODE long-RNA-seq pipeline.  Comments are from
            # the STAR docs.
            "--outFilterType BySJout "  # reduces number of spurious junctions
            "--outFilterMultimapNmax 20 "  # if more than this many multimappers, consider unmapped
            "--alignSJoverhangMin 8 "  # min overhang for unannotated junctions
            "--alignSJDBoverhangMin 1 "  # min overhang for annotated junctions
            "--outFilterMismatchNmax 999 "  # max mismatches per pair
            "--outFilterMismatchNoverReadLmax 0.04 "  # max mismatches per pair relative to read length
            "--alignIntronMin 20 "  # min intron length
            "--alignIntronMax 1000000 "  # max intron length
            "--alignMatesGapMax 1000000 "  # max distance between mates
            "--outSAMunmapped None "  # do not report aligned reads in output
            "2> {log} "
        )

        # move various hard-coded log files to log directory
        logfile_extensions = 
        logfiles = expand(
            prefix + "{ext}",
            ext=["Log.progress.out", "Log.out", "Log.final.out", "Log.std.out"]
        )
        shell(
            "mkdir -p {outdir}/star_logs "
            "&& mv {logfiles} {outdir}/star_logs"
        )


rule rRNA:
    input:
        fastq="data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz",
        index=multiext(
            f"{REFERENCES}/bowtie2/rrna",
            ".1.bt2",
            ".2.bt2",
            ".3.bt2",
            ".4.bt2",
            ".rev.1.bt2",
            ".rev.2.bt2",
            ".fa",
        ),
    output:
        bam="data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam",
    log:
        "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.log",
    threads: 6
    resources:
        mem="2g",
        runtime="2h",
    run:
        prefix = os.path.commonprefix(input.index).rstrip(".")
        sam = output.bam.replace(".bam", ".sam")
        shell(
            "bowtie2 "
            "-x {prefix} "
            "-U {input.fastq} "
            "--threads {threads} "
            "-k 1 "
            "--no-unal "
            "-S {sam} "
            "> {log} 2>&1"
        )

        shell(
            "samtools view -Sb {sam} "
            "| samtools sort - -o {output.bam} -O BAM "
            "&& rm {sam}"
        )


rule fastq_count:
    input:
        fastq="{sample_dir}/{sample}/{sample}{suffix}.fastq.gz",
    output:
        "{sample_dir}/{sample}/{sample}{suffix}.fastq.gz.libsize",
    threads: 1
    resources:
        mem="1g",
        runtime="2h",
    shell:
        "zcat {input} | echo $((`wc -l`/4)) > {output}"


rule bam_count:
    input:
        bam="{sample_dir}/{sample}/{suffix}.bam",
    output:
        "{sample_dir}/{sample}/{suffix}.bam.libsize",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "samtools view -c {input} > {output}"


rule bam_index:
    input:
        bam="{prefix}.bam",
    output:
        bai="{prefix}.bam.bai",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "samtools index {input} {output}"


rule markduplicates:
    input:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.bam",
    output:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam",
        metrics="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.metrics",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.log",
    threads: 1
    resources:
        mem="32g",
        runtime="2h",
        disk="100g",
    params:
        java_args="-Xmx20g",  # [disable for test]
        # java_args='-Xmx2g'  # [enable for test]
    shell:
        "picard "
        "{params.java_args} "
        "MarkDuplicates "
        "INPUT={input.bam} "
        "OUTPUT={output.bam} "
        "METRICS_FILE={output.metrics} "
        "VALIDATION_STRINGENCY=LENIENT "
        "&> {log}"


rule featurecounts:
    input:
        annotation=rules.gtf.output,
        bam=rules.markduplicates.output.bam,
    output:
        "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt",
    log:
        "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt.log",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    params:
        strand_arg={
            "unstranded": "-s0 ",
            "fr-firststrand": "-s2 ",
            "fr-secondstrand": "-s1 ",
        }[config["stranded"]],
        extra="",
    run:
        p_arg = ""
        if is_paired:
            p_arg = "-p --countReadPairs "
        shell(
            "featureCounts "
            "{params.strand_arg} "
            "{p_arg} "
            "-T {threads} "
            "-a {input.annotation} "
            "-o {output} "
            "{input.bam} "
            "&> {log}"
        )


rule aggregate_featurecounts:
    input:
        expand(
            "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt", sample=SAMPLES
        ),
    output:
        "data/rnaseq_aggregation/featurecounts.txt",
    log:
        "data/rnaseq_aggregation/featurecounts.txt.log",
    threads: 1
    resources:
        mem="8g",
        runtime="1h"
    run:
        for i, file in enumerate(input):
            df = pd.read_csv(file, sep="\t", comment="#")
            df = df.set_index("Geneid", drop=False)
            if i == 0:
                final = df
                continue
            final[df.columns[-1]] = df[df.columns[-1]]
        final.to_csv(output[0], sep="\t", index=False)


rule rrna_libsizes_table:
    input:
        rrna=expand(
            "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.libsize",
            sample=SAMPLES,
        ),
        fastq=expand(
            "data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz.libsize",
            sample=SAMPLES,
        ),
    output:
        tsv="data/rnaseq_aggregation/rrna_percentages_table.tsv",
        json="data/rnaseq_aggregation/rrna_percentages_table_mqc.yaml",
    threads: 1
    params:
        rrna_pattern=lambda wc: "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.libsize",
        fastq_pattern=lambda wc: "data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz.libsize",
    resources:
        mem="2g",
        runtime="2h",
    script:
        "../../scripts/rrna_libsizes_table.py"


rule collectrnaseqmetrics:
    input:
        bam=rules.markduplicates.output.bam,
        refflat=rules.conversion_refflat.output,
    output:
        metrics="data/rnaseq_samples/{sample}/{sample}.collectrnaseqmetrics.metrics",
    log:
        "data/rnaseq_samples/{sample}/{sample}.collectrnaseqmetrics.metrics.log",
    threads: 1
    resources:
        mem="32g",
        runtime="2h",
    params:
        java_args="-Xmx20g",  # [disable for test]
        # java_args='-Xmx2g',  # [enable for test]
        strand_arg={
            "unstranded": "STRAND=NONE ",
            "fr-firststrand": "STRAND=SECOND_READ_TRANSCRIPTION_STRAND ",
            "fr-secondstrand": "STRAND=FIRST_READ_TRANSCRIPTION_STRAND ",
        }[config["stranded"]],
    run:
        shell(
            "picard "
            "{params.java_args} "
            "CollectRnaSeqMetrics "
            "{params.strand_arg} "
            "VALIDATION_STRINGENCY=LENIENT "
            "REF_FLAT={input.refflat} "
            "INPUT={input.bam} "
            "OUTPUT={output.metrics} "
            "&> {log}"
        )


rule preseq:
    input:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam",
    output:
        "data/rnaseq_samples/{sample}/{sample}_preseq_c_curve.txt",
    log:
        "data/rnaseq_samples/{sample}/{sample}_preseq_c_curve.txt.log",
    threads: 1
    resources:
        mem="1g",
        runtime="2h",
    shell:
        "preseq "
        "c_curve "
        "-B {input} "
        "-o {output} "
        "&> {log}"


rule salmon:
    input:
        fastq=rules.cutadapt.output,
        index=REFERENCES + "/salmon/versionInfo.json",
    output:
        "data/rnaseq_samples/{sample}/{sample}.salmon/quant.sf",
    log:
        "data/rnaseq_samples/{sample}/{sample}.salmon/quant.sf.log",
    threads: 6
    resources:
        mem="32g",
        runtime="2h",
    run:
        outdir = os.path.dirname(output[0])
        index_dir = os.path.dirname(input.index)
        if is_paired:
            fastq_arg = f"-1 {input.fastq[0]} -2 {input.fastq[1]} "
        else:
            fastq_arg = f"-r {input.fastq} "
        shell(
            "salmon quant "
            "--index {index_dir} "
            "--output {outdir} "
            "--threads {threads} "
            "--libType=A "
            "--gcBias "
            "--seqBias "
            "--validateMappings "
            "{fastq_arg} "
            "&> {log}"
        )


rule kallisto:
    input:
        fastq=rules.cutadapt.output,
        index=REFERENCES + "/kallisto/transcripts.idx",
    output:
        "data/rnaseq_samples/{sample}/{sample}.kallisto/abundance.h5",
    log:
        "data/rnaseq_samples/{sample}/{sample}.kallisto/abundance.h5.log",
    threads: 8
    resources:
        mem="32g",
        runtime="2h",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--rf-stranded",
            "fr-secondstrand": "--fr-stranded",
        }[config["stranded"]],
        extra=(
            "--bootstrap-samples 100"
            if is_paired
            else "--single --fragment-length 300 --sd 20 --bootstrap-samples 100"
        ),
    run:
        outdir = os.path.dirname(output[0])
        shell(
            "kallisto quant "
            "--index {input.index} "
            "--output-dir {outdir} "
            "--threads {threads} "
            "--bootstrap-samples 100 "
            "--threads {threads} "
            "{params.strand_arg} "
            "{params.extra} "
            "{input.fastq} "
            "&> {log}"
        )


rule rseqc_infer_experiment:
    input:
        bam=rules.markduplicates.output,
        bed12=rules.conversion_bed12.output,
    output:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_infer_experiment.txt",
    log:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_infer_experiment.txt.log",
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "infer_experiment.py -r {input.bed12} -i {input.bam} > {output} &> {log}"


rule rseqc_read_distribution:
    input:
        bam=rules.markduplicates.output,
        bed12=rules.conversion_bed12.output,
    output:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_read_distribution.txt",
    log:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_read_distribution.txt.log",
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "read_distribution.py -i {input.bam} -r {input.bed12} > {output} &> {log}"


rule samtools_idxstats:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/idxstat_{sample}.txt",
    log:
        "data/rnaseq_samples/{sample}/idxstat_{sample}.txt.log",
    resources:
        mem="16g",
        runtime="2h",
    shell:
        "samtools idxstats {input.bam} 2> {log} 1> {output}"


rule samtools_flagstat:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.flagstat",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.flagstat.log",
    resources:
        mem="8g",
        runtime="2h",
    shell:
        "samtools flagstat {input.bam} > {output}"


rule samtools_stats:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.stats",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.stats.log",
    resources:
        mem="8g",
        runtime="2h",
    shell:
        "samtools stats {input.bam} > {output}"


rule bigwig_neg:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.neg.bigwig",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.neg.bigwig.log",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--filterRNAstrand reverse ",
            "fr-secondstrand": "--filterRNAstrand forward ",
        }[config["stranded"]],
    run:
        shell(
            "bamCoverage "
            "--bam {input.bam} "
            "-o {output} "
            "-p {threads} "
            "{params.strand_arg} "
            "--minMappingQuality 20 "
            "--smoothLength 10 "
            "--normalizeUsing BPM "  # [disable for test]
            "&> {log}"
        )


rule bigwig_pos:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.pos.bigwig",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.pos.bigwig.log",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--filterRNAstrand forward ",
            "fr-secondstrand": "--filterRNAstrand reverse ",
        }[config["stranded"]],
    run:
        shell(
            "bamCoverage "
            "--bam {input.bam} "
            "-o {output} "
            "-p {threads} "
            "--minMappingQuality 20 "
            "--smoothLength 10 "
            "--normalizeUsing BPM "  # [disable for test]
            "{params.strand_arg} "
            "&> {log}"
        )


rule multiqc:
    input:
        files=(
            expand(
                rules.fastqc.output.zip,
                sample=SAMPLES,
                suffix=["_R1.fastq.gz", "_R1.cutadapt.fastq.gz", ".cutadapt.bam"],
            ),
            expand(rules.markduplicates.output, sample=SAMPLES),
            expand(rules.salmon.output, sample=SAMPLES),
            expand(rules.kallisto.output, sample=SAMPLES),
            expand(rules.preseq.output, sample=SAMPLES),
            expand(rules.collectrnaseqmetrics.output, sample=SAMPLES),
            expand(rules.samtools_stats.output, sample=SAMPLES),
            expand(rules.samtools_flagstat.output, sample=SAMPLES),
            expand(rules.samtools_idxstats.output, sample=SAMPLES),
            expand(rules.rseqc_infer_experiment.output, sample=SAMPLES),
            expand(rules.rseqc_read_distribution.output, sample=SAMPLES),
            expand(rules.bigwig_pos.output, sample=SAMPLES),
            expand(rules.bigwig_neg.output, sample=SAMPLES),
            rules.rrna_libsizes_table.output,
        ),
        config="config/multiqc_config.yaml",
    output:
        "data/rnaseq_aggregation/multiqc.html",
    log:
        "data/rnaseq_aggregation/multiqc.log",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
        disk="10g",
    run:
        analysis_directory = set([os.path.dirname(i) for i in input])
        outdir = os.path.dirname(output[0])
        basename = os.path.basename(output[0])
        shell(
            "LC_ALL=en_US.utf8 LC_LANG=en_US.utf8 "
            "multiqc "
            "--quiet "
            "--outdir {outdir} "
            "--force "
            "--filename {basename} "
            "--config {input.config} "
            "{analysis_directory} "
            "&> {log} "
        )

import sys
import os
import yaml
import pandas as pd

sys.path.insert(0, os.path.dirname(workflow.snakefile) + "/../..")
from lib import utils


configfile: "config/config.yaml"


REFERENCES = config.get("reference_dir", "../../references")
sampletable = pd.read_table(config["sampletable"], sep="\t", comment="#")
sampletable = sampletable.set_index(sampletable.columns[0], drop=False)
is_paired = utils.detect_layout(sampletable) == "PE"
n = ["1", "2"] if is_paired else ["1"]
SAMPLES = sampletable.index


wildcard_constraints:
    n="[1,2]",
    sample="|".join(SAMPLES),


localrules:
    symlinks,
    symlink_targets,


rule all:
    input:
        "data/rnaseq_aggregation/multiqc.html",


include: "../references/Snakefile"


if utils.detect_sra(sampletable):
    sampletable["orig_filename"] = expand(
        "original_data/sra_samples/{sample}/{sample}_R{n}.fastq.gz", sample=SAMPLES, n=1
    )

    if is_paired:
        sampletable["orig_filename_R2"] = expand(
            "original_data/sra_samples/{sample}/{sample}_R{n}.fastq.gz",
            sample=SAMPLES,
            n=2,
        )

    rule fastq_dump:
        output:
            fastq=expand(
                "original_data/sra_samples/{sample}/{sample}_R{n}.fastq.gz",
                n=n,
                allow_missing=True,
            ),
        log:
            "original_data/sra_samples/{sample}/{sample}.fastq.gz.log",
        params:
            is_paired=is_paired,
            # extra="-X 100000",  # [enable for test]
        resources:
            mem="1g",
            disk="1g",
            runtime="2h",
        run:
            srr = sampletable.loc[wildcards.sample, "Run"]
            extra = params.get("extra", "")
            if is_paired:
                shell("fastq-dump {srr} --gzip --split-files {extra} &> {log}")
                shell("mv {srr}_1.fastq.gz {output[0]}")
                shell("mv {srr}_2.fastq.gz {output[1]}")
            else:
                shell(
                    "fastq-dump {srr} -Z {extra} 2> {log} | gzip -c > {output[0]}.tmp"
                )
                shell("mv {output[0]}.tmp {output[0]}")



rule symlinks:
    input:
        lambda wc: (
            sampletable.loc[wc.sample, ["orig_filename", "orig_filename_R2"]]
            if is_paired
            else sampletable.loc[wc.sample, ["orig_filename"]]
        ),
    output:
        expand("data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.fastq.gz", n=n),
    threads: 1
    resources:
        mem="1g",
        runtime="10m",
    run:
        assert len(output) == len(input), (input, output)
        for src, linkname in zip(input, output):
            utils.make_relative_symlink(src, linkname)


rule symlink_targets:
    input:
        expand(
            "data/rnaseq_samples/{sample}/{sample}_R{n}.fastq.gz", sample=SAMPLES, n=n
        ),


# Optionally run ``snakemake strand_check`` to do a preliminary run on
# automatically-subset data to evaluate strandedness.
rule sample_strand_check:
    input:
        fastq=expand("data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.fastq.gz", n=n),
        index=expand(rules.bowtie2_index.output, label="genome"),
        bed12=rules.conversion_bed12.output,
    output:
        strandedness="strand_check/{sample}/{sample}.strandedness",
        bam=temporary("strand_check/{sample}/{sample}.strandedness.bam"),
        bai=temporary("strand_check/{sample}/{sample}.strandedness.bam.bai"),
        fastqs=temporary(
            expand(
                "strand_check/{sample}/{sample}_R{n}.strandedness.fastq",
                n=n,
                allow_missing=True,
            )
        ),
    log:
        "strand_check/{sample}/{sample}.strandedness.log",
    threads: 6
    resources:
        mem="8g",
        runtime="2h",
    run:
        prefix = os.path.commonprefix(input.index).rstrip(".")
        nreads = int(1e5 * 4)
        if is_paired:
            shell(
                "set +o pipefail; zcat {input.fastq[0]} | head -n {nreads} > {output.fastqs[0]}"
            )
            shell(
                "set +o pipefail; zcat {input.fastq[0]} | head -n {nreads} > {output.fastqs[1]}"
            )
            fastqs = f"-1 {output.fastqs[0]} -2 {output.fastqs[1]} "
        else:
            shell(
                "set +o pipefail; zcat {input.fastq[0]} | head -n {nreads} > {output.fastqs[0]}"
            )
            fastqs = f"-U {output.fastqs[0]} "
        shell(
            "bowtie2 "
            "-x {prefix} "
            "{fastqs} "
            "--no-unal "
            "--threads {threads} 2> {log} "
            "| samtools view -Sb - "
            "| samtools sort - -o {output.bam} "
        )
        shell("samtools index {output.bam}")
        shell(
            "infer_experiment.py -r {input.bed12} -i {output.bam} > {output} 2> {log}"
        )


rule strand_check:
    input:
        expand("strand_check/{sample}/{sample}.strandedness", sample=SAMPLES),
    output:
        html="strand_check/strandedness.html",
        filelist=temporary("strand_check/filelist"),
    log:
        "strand_check/strandedness.log",
    resources:
        mem="1g",
        runtime="2h",
    run:
        with open(output.filelist, "w") as fout:
            for i in input:
                fout.write(i + "\n")
        shell(
            "multiqc "
            "--force "
            "--module rseqc "
            "--file-list {output.filelist} "
            "--filename {output.html} &> {log}"
        )


rule cutadapt:
    input:
        fastq=expand("data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.fastq.gz", n=n),
    output:
        fastq=expand(
            "data/rnaseq_samples/{{sample}}/{{sample}}_R{n}.cutadapt.fastq.gz", n=n
        ),
    log:
        "data/rnaseq_samples/{sample}/{sample}_cutadapt.fastq.gz.log",
    threads: 6
    resources:
        mem="2g",
        runtime="2h",
    params:
        extra=(
            (
                "--nextseq-trim 20 "
                "--overlap 6 "
                "--minimum-length 25 "
                "-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA "
            )
            + "-A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT "
            if is_paired
            else ""
        ),
    run:
        if is_paired:
            shell(
                "cutadapt "
                "-o {output[0]} "
                "-p {output[1]} "
                "-j {threads} "
                "{params.extra} "
                "{input.fastq[0]} "
                "{input.fastq[1]} "
                "&> {log}"
            )
        else:
            shell(
                "cutadapt "
                "-o {output[0]} "
                "-j {threads} "
                "{params.extra} "
                "{input.fastq[0]} "
                "&> {log}"
            )


rule fastqc:
    input:
        "data/rnaseq_samples/{sample}/{sample}{suffix}",
    threads: 1
    output:
        html="data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.html",
        zip="data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.zip",
    resources:
        mem="8g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/fastqc/{sample}{suffix}_fastqc.log",
    run:
        outdir = os.path.dirname(output.html) or "."
        shell(
            "fastqc "
            "--noextract "
            "--quiet "
            "--outdir {outdir} "
            "{input} "
            "2> {log} "
        )
        outfile = os.path.basename(input[0])
        for s in [".fastq", ".fq", ".gz", ".bam"]:
            outfile = outfile.replace(s, "")
        out_zip = os.path.join(outdir, outfile + "_fastqc.zip")
        if not os.path.abspath(out_zip) == os.path.abspath(output.zip):
            shell("mv {out_zip} {output.zip}")
        out_html = os.path.join(outdir, outfile + "_fastqc.html")
        if not os.path.abspath(out_html) == os.path.abspath(output.html):
            shell("mv {out_html} {output.html}")


if config["aligner"] == "hisat2":

    rule hisat2:
        input:
            fastq=rules.cutadapt.output,
            index=rules.hisat2_index.output,
        output:
            bam=temporary("data/rnaseq_samples/{sample}/{sample}.cutadapt.bam"),
        log:
            "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.log",
        threads: 16
        resources:
            mem="32g",
            runtime="8h",
        params:
            extra="",
        run:
            prefix = os.path.commonprefix(input.index).rstrip(".")
            sam = output.bam.replace(".bam", ".sam")

            if is_paired:
                assert len(input.fastq) == 2
                fastqs = "-1 {0} -2 {1} ".format(*input.fastq)
            else:
                assert len(input.fastq) == 1
                fastqs = "-U {0} ".format(input.fastq)

            shell(
                "hisat2 "
                "-x {prefix} "
                "{fastqs} "
                "--no-unal "
                "--threads {threads} "
                "-S {sam} "
                "{params.extra} "
                "> {log} 2>&1"
            )

            shell(
                "samtools view -Sb {sam} "
                "| samtools sort - -o {output.bam} -O BAM "
                "&& rm {sam}"
            )



if config["aligner"].startswith("star"):
    if os.getenv("TMPDIR"):
        tmpdir_arg = "--outTmpDir $TMPDIR/star "
    else:
        tmpdir_arg = ""
    # STAR can be run in 1-pass or 2-pass modes. Since we may be running it
    # more than once in almost the same way, we pull out the shell command here
    # and use it below.
    STAR_CMD = (
        "STAR "
        "--runThreadN {threads} "
        "--genomeDir {genomedir} "
        "--readFilesIn {input.fastq} "
        "--readFilesCommand zcat "
        "--outFileNamePrefix {prefix} "
        "{tmpdir_arg} "
        "{params.extra} "
    )
    STAR_PARAMS = (
        # NOTE: The STAR docs indicate that the following parameters are
        # standard options for ENCODE long-RNA-seq pipeline.  Comments are from
        # the STAR docs.
        "--outFilterType BySJout "  # reduces number of spurious junctions
        "--outFilterMultimapNmax 20 "  # if more than this many multimappers, consider unmapped
        "--alignSJoverhangMin 8 "  # min overhang for unannotated junctions
        "--alignSJDBoverhangMin 1 "  # min overhang for annotated junctions
        "--outFilterMismatchNmax 999 "  # max mismatches per pair
        "--outFilterMismatchNoverReadLmax 0.04 "  # max mismatches per pair relative to read length
        "--alignIntronMin 20 "  # min intron length
        "--alignIntronMax 1000000 "  # max intron length
        "--alignMatesGapMax 1000000 "  # max distance between mates
        "--outSAMunmapped None "  # do not report aligned reads in output
    )
    logfile_extensions = ["Log.progress.out", "Log.out", "Log.final.out", "Log.std.out"]

if config["aligner"] == "star":

    rule star:
        "Align with STAR (1-pass mode)"
        input:
            fastq=rules.cutadapt.output,
            index=rules.star_index.output,
            annotation=f"{REFERENCES}/annotation.gtf",
        output:
            bam=temporary("data/rnaseq_samples/{sample}/{sample}.cutadapt.bam"),
            sjout=temporary(
                "data/rnaseq_samples/{sample}/{sample}.cutadapt.star.SJ.out.tab"
            ),
        log:
            "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.log",
        threads: 16
        resources:
            mem="64g",
            runtime="8h",
            disk="80g",
        params:
            extra=STAR_PARAMS,
        run:
            genomedir = os.path.dirname(input.index[0])
            outdir = os.path.dirname(output[0])
            prefix = output.bam.replace(".bam", ".star.")
            shell(
                STAR_CMD
                + (
                    "--outSAMtype BAM SortedByCoordinate "
                    "--outStd BAM_SortedByCoordinate > {output.bam} "
                    "2> {log} "
                )
            )

            # move various hard-coded log files to log directory
            logfiles = expand(prefix + "{ext}", ext=logfile_extensions)
            shell(
                "mkdir -p {outdir}/star_logs " "&& mv {logfiles} {outdir}/star_logs"
            )


if config["aligner"] == "star-twopass":

    rule star_pass1:
        "First pass of alignment with STAR to get the junctions"
        input:
            fastq=rules.cutadapt.output,
            index=rules.star_index.output,
            annotation=f"{REFERENCES}/annotation.gtf",
        output:
            sjout=temporary(
                "data/rnaseq_samples/{sample}/{sample}.cutadapt.star.SJ.out.tab"
            ),
        log:
            "data/rnaseq_samples/{sample}/{sample}.cutadapt.star-pass1.log",
        threads: 16
        resources:
            mem="64g",
            runtime="8h",
            disk="80g",
        params:
            extra=STAR_PARAMS,
        run:
            genomedir = os.path.dirname(input.index[0])
            outdir = os.path.dirname(output[0])
            prefix = output.sjout.replace("SJ.out.tab", "")
            shell(
                STAR_CMD
                + (
                    # In this first pass, we don't actually care about the
                    # alignment -- just the detected junctions. So we output
                    # the SAM to /dev/null.
                    "--outStd SAM > /dev/null "
                    "2> {log} "
                )
            )

            # move various hard-coded log files to log directory
            logfiles = expand(prefix + "{ext}", ext=logfile_extensions)
            shell(
                "mkdir -p {outdir}/star-pass1_logs "
                "&& mv {logfiles} {outdir}/star-pass1_logs"
            )

    rule star_pass2:
        """
        Second pass of alignment with STAR using splice junctions across all
        samples to get the final BAM
        """
        input:
            fastq=rules.cutadapt.output,
            index=rules.star_index.output,
            annotation=f"{REFERENCES}/annotation.gtf",
            sjout=expand(rules.star_pass1.output, sample=SAMPLES),
        output:
            bam=temporary("data/rnaseq_samples/{sample}/{sample}.cutadapt.bam"),
            sjout=temporary(
                "data/rnaseq_samples/{sample}/{sample}.cutadapt.star-pass2.SJ.out.tab"
            ),
        log:
            "data/rnaseq_samples/{sample}/{sample}.cutadapt.star-pass2.log",
        threads: 16
        resources:
            mem="64g",
            runtime="8h",
            disk="80g",
        params:
            extra=STAR_PARAMS,
        run:
            genomedir = os.path.dirname(input.index[0])
            outdir = os.path.dirname(output[0])
            prefix = output.bam.replace(".bam", ".star-pass2.")
            shell(
                STAR_CMD
                + (
                    # In contrast to pass 1, we will be keeping these BAMs --
                    # so sort them
                    "--outSAMtype BAM SortedByCoordinate "
                    # Splice junction databases from all samples in the first
                    # pass.
                    "--sjdbFileChrStartEnd {input.sjout} "
                    "--outStd BAM_SortedByCoordinate > {output.bam} "
                    "2> {log} "
                )
            )

            # move various hard-coded log files to log directory
            logfiles = expand(prefix + "{ext}", ext=logfile_extensions)
            shell(
                "mkdir -p {outdir}/star-pass2_logs "
                "&& mv {logfiles} {outdir}/star-pass2_logs"
            )

            shell("rm -r {prefix}_STARgenome")


rule rRNA:
    input:
        fastq="data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz",
        index=multiext(
            f"{REFERENCES}/bowtie2/rrna",
            ".1.bt2",
            ".2.bt2",
            ".3.bt2",
            ".4.bt2",
            ".rev.1.bt2",
            ".rev.2.bt2",
            ".fa",
        ),
    output:
        bam="data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam",
    log:
        "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.log",
    threads: 6
    resources:
        mem="2g",
        runtime="2h",
    params:
        extra=(
            "-k 1 "
            "--no-unal "
        ),
    run:
        prefix = os.path.commonprefix(input.index).rstrip(".")
        sam = output.bam.replace(".bam", ".sam")

        shell(
            "bowtie2 "
            "-x {prefix} "
            "-U {input.fastq} "
            "--threads {threads} "
            "{params.extra} "
            "-S {sam} "
            "> {log} 2>&1"
        )

        shell(
            "samtools view -Sb {sam} "
            "| samtools sort - -o {output.bam} -O BAM "
            "&& rm {sam}"
        )


rule fastq_count:
    input:
        fastq="{sample_dir}/{sample}/{sample}{suffix}.fastq.gz",
    output:
        "{sample_dir}/{sample}/{sample}{suffix}.fastq.gz.libsize",
    threads: 1
    resources:
        mem="1g",
        runtime="2h",
    shell:
        "zcat {input} | echo $((`wc -l`/4)) > {output}"


rule bam_count:
    input:
        bam="{sample_dir}/{sample}/{suffix}.bam",
    output:
        "{sample_dir}/{sample}/{suffix}.bam.libsize",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "samtools view -c {input} > {output}"


rule bam_index:
    input:
        bam="{prefix}.bam",
    output:
        bai="{prefix}.bam.bai",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "samtools index {input} {output}"


rule markduplicates:
    input:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.bam",
    output:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam",
        metrics="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.metrics",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.log",
    threads: 1
    resources:
        mem="32g",
        runtime="2h",
        disk="100g",
    params:
        java_args="-Xmx20g",  # [disable for test]
        # java_args='-Xmx2g'  # [enable for test]
    shell:
        "picard "
        "{params.java_args} "
        "MarkDuplicates "
        "INPUT={input.bam} "
        "OUTPUT={output.bam} "
        "METRICS_FILE={output.metrics} "
        "VALIDATION_STRINGENCY=LENIENT "
        "&> {log}"


rule featurecounts:
    input:
        annotation=rules.gtf.output,
        bam=rules.markduplicates.output.bam,
    output:
        "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt",
    log:
        "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt.log",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    params:
        strand_arg={
            "unstranded": "-s0 ",
            "fr-firststrand": "-s2 ",
            "fr-secondstrand": "-s1 ",
        }[config["stranded"]],
        extra="",
    run:
        p_arg = ""
        if is_paired:
            p_arg = "-p --countReadPairs "
        shell(
            "featureCounts "
            "{params.strand_arg} "
            "{p_arg} "
            "-T {threads} "
            "-a {input.annotation} "
            "-o {output} "
            "{input.bam} "
            "&> {log}"
        )


rule aggregate_featurecounts:
    input:
        expand(
            "data/rnaseq_samples/{sample}/{sample}_featurecounts.txt", sample=SAMPLES
        ),
    output:
        "data/rnaseq_aggregation/featurecounts.txt",
    log:
        "data/rnaseq_aggregation/featurecounts.txt.log",
    threads: 1
    resources:
        mem="8g",
        runtime="1h"
    run:
        for i, file in enumerate(input):
            df = pd.read_csv(file, sep="\t", comment="#")
            df = df.set_index("Geneid", drop=False)
            if i == 0:
                final = df
                continue
            final[df.columns[-1]] = df[df.columns[-1]]
        final.to_csv(output[0], sep="\t", index=False)


rule rrna_libsizes_table:
    input:
        rrna=expand(
            "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.libsize",
            sample=SAMPLES,
        ),
        fastq=expand(
            "data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz.libsize",
            sample=SAMPLES,
        ),
    output:
        tsv="data/rnaseq_aggregation/rrna_percentages_table.tsv",
        json="data/rnaseq_aggregation/rrna_percentages_table_mqc.yaml",
    threads: 1
    params:
        rrna_pattern=lambda wc: "data/rnaseq_samples/{sample}/rRNA/{sample}.cutadapt.rrna.bam.libsize",
        fastq_pattern=lambda wc: "data/rnaseq_samples/{sample}/{sample}_R1.cutadapt.fastq.gz.libsize",
    resources:
        mem="2g",
        runtime="2h",
    script:
        "../../scripts/rrna_libsizes_table.py"


rule collectrnaseqmetrics:
    input:
        bam=rules.markduplicates.output.bam,
        refflat=rules.conversion_refflat.output,
    output:
        metrics="data/rnaseq_samples/{sample}/{sample}.collectrnaseqmetrics.metrics",
    log:
        "data/rnaseq_samples/{sample}/{sample}.collectrnaseqmetrics.metrics.log",
    threads: 1
    resources:
        mem="32g",
        runtime="2h",
    params:
        java_args="-Xmx20g",  # [disable for test]
        # java_args='-Xmx2g',  # [enable for test]
        strand_arg={
            "unstranded": "STRAND=NONE ",
            "fr-firststrand": "STRAND=SECOND_READ_TRANSCRIPTION_STRAND ",
            "fr-secondstrand": "STRAND=FIRST_READ_TRANSCRIPTION_STRAND ",
        }[config["stranded"]],
    run:
        shell(
            "picard "
            "{params.java_args} "
            "CollectRnaSeqMetrics "
            "{params.strand_arg} "
            "VALIDATION_STRINGENCY=LENIENT "
            "REF_FLAT={input.refflat} "
            "INPUT={input.bam} "
            "OUTPUT={output.metrics} "
            "&> {log}"
        )


rule preseq:
    input:
        bam="data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam",
    output:
        "data/rnaseq_samples/{sample}/{sample}_preseq_c_curve.txt",
    log:
        "data/rnaseq_samples/{sample}/{sample}_preseq_c_curve.txt.log",
    threads: 1
    resources:
        mem="1g",
        runtime="2h",
    shell:
        "preseq "
        "c_curve "
        "-B {input} "
        "-o {output} "
        "&> {log}"


rule salmon:
    input:
        fastq=rules.cutadapt.output,
        index=REFERENCES + "/salmon/versionInfo.json",
    output:
        "data/rnaseq_samples/{sample}/{sample}.salmon/quant.sf",
    log:
        "data/rnaseq_samples/{sample}/{sample}.salmon/quant.sf.log",
    threads: 6
    resources:
        mem="32g",
        runtime="2h",
    params:
        extra=(
            "--libType=A "
            "--gcBias "
            "--seqBias "
            "--validateMappings "
        ),
    run:
        outdir = os.path.dirname(output[0])
        index_dir = os.path.dirname(input.index)
        if is_paired:
            fastq_arg = f"-1 {input.fastq[0]} -2 {input.fastq[1]} "
        else:
            fastq_arg = f"-r {input.fastq} "
        shell(
            "salmon quant "
            "--index {index_dir} "
            "--output {outdir} "
            "--threads {threads} "
            "{params.extra} "
            "{fastq_arg} "
            "&> {log}"
        )


rule kallisto:
    input:
        fastq=rules.cutadapt.output,
        index=REFERENCES + "/kallisto/transcripts.idx",
    output:
        "data/rnaseq_samples/{sample}/{sample}.kallisto/abundance.h5",
    log:
        "data/rnaseq_samples/{sample}/{sample}.kallisto/abundance.h5.log",
    threads: 8
    resources:
        mem="32g",
        runtime="2h",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--rf-stranded",
            "fr-secondstrand": "--fr-stranded",
        }[config["stranded"]],
        extra=(
            "--bootstrap-samples 100"
            if is_paired
            else "--single --fragment-length 300 --sd 20 --bootstrap-samples 100"
        ),
    run:
        outdir = os.path.dirname(output[0])
        shell(
            "kallisto quant "
            "--index {input.index} "
            "--output-dir {outdir} "
            "--threads {threads} "
            "--bootstrap-samples 100 "
            "--threads {threads} "
            "{params.strand_arg} "
            "{params.extra} "
            "{input.fastq} "
            "&> {log}"
        )


rule rseqc_infer_experiment:
    input:
        bam=rules.markduplicates.output,
        bed12=rules.conversion_bed12.output,
    output:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_infer_experiment.txt",
    log:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_infer_experiment.txt.log",
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "infer_experiment.py -r {input.bed12} -i {input.bam} > {output} &> {log}"


rule rseqc_read_distribution:
    input:
        bam=rules.markduplicates.output,
        bed12=rules.conversion_bed12.output,
    output:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_read_distribution.txt",
    log:
        "data/rnaseq_samples/{sample}/rseqc/{sample}_read_distribution.txt.log",
    resources:
        mem="2g",
        runtime="2h",
    shell:
        "read_distribution.py -i {input.bam} -r {input.bed12} > {output} &> {log}"


rule samtools_idxstats:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/idxstat_{sample}.txt",
    log:
        "data/rnaseq_samples/{sample}/idxstat_{sample}.txt.log",
    resources:
        mem="16g",
        runtime="2h",
    shell:
        "samtools idxstats {input.bam} 2> {log} 1> {output}"


rule samtools_flagstat:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.flagstat",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.flagstat.log",
    resources:
        mem="8g",
        runtime="2h",
    shell:
        "samtools flagstat {input.bam} > {output}"


rule samtools_stats:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.stats",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.markdups.bam.stats.log",
    resources:
        mem="8g",
        runtime="2h",
    shell:
        "samtools stats {input.bam} > {output}"


rule bigwig_neg:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.neg.bigwig",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.neg.bigwig.log",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--filterRNAstrand reverse ",
            "fr-secondstrand": "--filterRNAstrand forward ",
        }[config["stranded"]],
        extra=(
            "--minMappingQuality 20 "
            "--smoothLength 10 "
            "--normalizeUsing BPM "  # [disable for test]
        ),
    run:
        shell(
            "bamCoverage "
            "--bam {input.bam} "
            "-o {output} "
            "-p {threads} "
            "{params.extra} "
            "{params.strand_arg} "
            "&> {log}"
        )


rule bigwig_pos:
    input:
        bam=rules.markduplicates.output.bam,
        bai=rules.markduplicates.output.bam + ".bai",
    output:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.pos.bigwig",
    threads: 8
    resources:
        mem="16g",
        runtime="2h",
    log:
        "data/rnaseq_samples/{sample}/{sample}.cutadapt.bam.pos.bigwig.log",
    params:
        strand_arg={
            "unstranded": "",
            "fr-firststrand": "--filterRNAstrand forward ",
            "fr-secondstrand": "--filterRNAstrand reverse ",
        }[config["stranded"]],
        extra=(
            "--minMappingQuality 20 "
            "--smoothLength 10 "
            "--normalizeUsing BPM "  # [disable for test]
        ),
    run:
        shell(
            "bamCoverage "
            "--bam {input.bam} "
            "-o {output} "
            "-p {threads} "
            "{params.extra} "
            "{params.strand_arg} "
            "&> {log}"
        )


rule multiqc:
    input:
        files=(
            expand(
                rules.fastqc.output.zip,
                sample=SAMPLES,
                suffix=["_R1.fastq.gz", "_R1.cutadapt.fastq.gz", ".cutadapt.bam"],
            ),
            expand(rules.markduplicates.output, sample=SAMPLES),
            expand(rules.salmon.output, sample=SAMPLES),
            expand(rules.kallisto.output, sample=SAMPLES),
            expand(rules.preseq.output, sample=SAMPLES),
            expand(rules.collectrnaseqmetrics.output, sample=SAMPLES),
            expand(rules.samtools_stats.output, sample=SAMPLES),
            expand(rules.samtools_flagstat.output, sample=SAMPLES),
            expand(rules.samtools_idxstats.output, sample=SAMPLES),
            expand(rules.rseqc_infer_experiment.output, sample=SAMPLES),
            expand(rules.rseqc_read_distribution.output, sample=SAMPLES),
            expand(rules.bigwig_pos.output, sample=SAMPLES),
            expand(rules.bigwig_neg.output, sample=SAMPLES),
            rules.rrna_libsizes_table.output,
        ),
        config="config/multiqc_config.yaml",
    output:
        "data/rnaseq_aggregation/multiqc.html",
    log:
        "data/rnaseq_aggregation/multiqc.log",
    threads: 1
    resources:
        mem="2g",
        runtime="2h",
        disk="10g",
    run:
        analysis_directory = set([os.path.dirname(i) for i in input])
        outdir = os.path.dirname(output[0])
        basename = os.path.basename(output[0])
        shell(
            "LC_ALL=en_US.utf8 LC_LANG=en_US.utf8 "
            "multiqc "
            "--quiet "
            "--outdir {outdir} "
            "--force "
            "--filename {basename} "
            "--config {input.config} "
            "{analysis_directory} "
            "&> {log} "
        )
